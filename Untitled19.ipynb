{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Vv9nIXiDUiqV"
      },
      "outputs": [],
      "source": [
        "#code for getting images from videos and saving them in for_images file,later will be used for testing\n",
        "import cv2\n",
        "import os\n",
        " \n",
        "# Camera Settings\n",
        "camera_Width  = 640 # 1024 # 1280 # 640\n",
        "camera_Heigth = 480 # 780  # 960  # 480\n",
        "frameSize = (camera_Width, camera_Heigth)\n",
        "video_file = \"baseball_1.mp4\"\n",
        "video_capture = cv2.VideoCapture(video_file)\n",
        " \n",
        "i = 0\n",
        "while video_capture.isOpened():\n",
        " \n",
        "    ret, frameOrig = video_capture.read()\n",
        "    if ret == True:\n",
        "        # resize frame, optional you may not need this\n",
        "        frame = cv2.resize(frameOrig, frameSize)\n",
        " \n",
        "        i += 1\n",
        "        imgNumber = str(i).zfill(5)\n",
        "        #frameImageFileName = str(f'03\\image{imgNumber}.png')\n",
        "        frameImageFileName = os.path.join('/content/for_images', 'image{}.png'.format(imgNumber))\n",
        "\n",
        "        cv2.imwrite(frameImageFileName, frameOrig)\n",
        " \n",
        "        #cv2.imshow('Video', frame)\n",
        "    else:\n",
        "        break\n",
        " \n",
        "    # key controller\n",
        "    key = cv2.waitKey(1) & 0xFF   \n",
        "    if key == ord(\"q\"):\n",
        "        break\n",
        " \n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale =1./255,\n",
        "                                   shear_range =0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip =True)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "metadata": {
        "id": "3ro6M9nwVMe-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/dataset_mt/train_images',\n",
        "                                                target_size=(64,64),\n",
        "                                                batch_size= 500,\n",
        "                                                class_mode='categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/dataset_mt/test_images',\n",
        "                                           target_size = (64,64),\n",
        "                                           batch_size = 500,\n",
        "                                           class_mode ='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJixqCgiVetl",
        "outputId": "87b0f018-7ade-4400-9b12-a4f160bb32b6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10843 images belonging to 5 classes.\n",
            "Found 2398 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,Activation,MaxPooling2D,Dense,Flatten,Dropout\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "8v-FWx9AaXga"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqcRANKhJooh",
        "outputId": "3e21cb8c-0f88-4c01-cc6c-e19395245936"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 64, 64, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = Sequential()\n"
      ],
      "metadata": {
        "id": "O_DJbPX2ag2v"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.add(Conv2D(32,(3,3),input_shape=(64,64,3)))\n",
        "classifier.add(Activation('sigmoid'))\n",
        "classifier.add(MaxPooling2D(pool_size =(2,2)))\n",
        "classifier.add(Dropout(0.25))\n",
        "\n",
        "classifier.add(Conv2D(64,(3,3))) \n",
        "classifier.add(Activation('sigmoid'))\n",
        "classifier.add(MaxPooling2D(pool_size =(2,2)))\n",
        "classifier.add(Dropout(0.25))\n",
        "\n",
        "classifier.add(Conv2D(128,(3,3))) \n",
        "classifier.add(Activation('sigmoid'))\n",
        "classifier.add(MaxPooling2D(pool_size =(2,2)))\n",
        "classifier.add(Dropout(0.25))\n",
        "\n",
        "classifier.add(Flatten())\n",
        "classifier.add(Dense(4608))\n",
        "classifier.add(Activation('sigmoid'))\n",
        "classifier.add(Dropout(0.5))\n",
        "classifier.add(Dense(128))\n",
        "#classifier.add(Dropout(0.5))\n",
        "\n",
        "classifier.add(Dense(5))\n",
        "classifier.add(Activation('sigmoid'))\n"
      ],
      "metadata": {
        "id": "u2H49Hh3aigM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQlAsrdonenJ",
        "outputId": "991dcf93-ae5e-453a-f885-33a99e8e3330"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 62, 62, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 31, 31, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 31, 31, 32)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 29, 29, 64)        18496     \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 29, 29, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 14, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 12, 12, 128)       73856     \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 6, 6, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 6, 6, 128)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4608)              21238272  \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 4608)              0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               589952    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,922,117\n",
            "Trainable params: 21,922,117\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.compile(optimizer ='rmsprop',\n",
        "                   loss ='categorical_crossentropy',\n",
        "                   metrics =['accuracy'])"
      ],
      "metadata": {
        "id": "572rFeb4a2na"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "classifier.fit_generator(training_set,\n",
        "                        epochs = 15,\n",
        "                        validation_data =test_set,\n",
        "                        validation_steps = 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onS5JA0ja4zh",
        "outputId": "9af4fb39-15f6-449a-c53f-cccc5dba6d47"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-5e7e00c912bf>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  classifier.fit_generator(training_set,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "22/22 [==============================] - 195s 9s/step - loss: 1.4871 - accuracy: 0.3839\n",
            "Epoch 2/15\n",
            "22/22 [==============================] - 199s 9s/step - loss: 1.4853 - accuracy: 0.3836\n",
            "Epoch 3/15\n",
            "22/22 [==============================] - 198s 9s/step - loss: 1.4831 - accuracy: 0.3836\n",
            "Epoch 4/15\n",
            "22/22 [==============================] - 203s 9s/step - loss: 1.4831 - accuracy: 0.3836\n",
            "Epoch 5/15\n",
            "22/22 [==============================] - 200s 9s/step - loss: 1.4828 - accuracy: 0.3836\n",
            "Epoch 6/15\n",
            "22/22 [==============================] - 199s 9s/step - loss: 1.4830 - accuracy: 0.3836\n",
            "Epoch 7/15\n",
            "22/22 [==============================] - 199s 9s/step - loss: 1.4829 - accuracy: 0.3836\n",
            "Epoch 8/15\n",
            "22/22 [==============================] - 199s 9s/step - loss: 1.4814 - accuracy: 0.3836\n",
            "Epoch 9/15\n",
            "22/22 [==============================] - 199s 9s/step - loss: 1.4820 - accuracy: 0.3836\n",
            "Epoch 10/15\n",
            "22/22 [==============================] - 200s 9s/step - loss: 1.4823 - accuracy: 0.3836\n",
            "Epoch 11/15\n",
            "22/22 [==============================] - 200s 9s/step - loss: 1.4822 - accuracy: 0.3836\n",
            "Epoch 12/15\n",
            "22/22 [==============================] - 201s 9s/step - loss: 1.4812 - accuracy: 0.3836\n",
            "Epoch 13/15\n",
            "22/22 [==============================] - 199s 9s/step - loss: 1.4820 - accuracy: 0.3836\n",
            "Epoch 14/15\n",
            "22/22 [==============================] - 212s 9s/step - loss: 1.4814 - accuracy: 0.3836\n",
            "Epoch 15/15\n",
            "22/22 [==============================] - 202s 9s/step - loss: 1.4810 - accuracy: 0.3836\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8e18dd25e0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.save('cnn_model.h5')\n"
      ],
      "metadata": {
        "id": "2cNo46oIa8FJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow import keras\n"
      ],
      "metadata": {
        "id": "Xk3gahEuECk2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import load_img\n"
      ],
      "metadata": {
        "id": "2BV7grpBFTj4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "test_image =image.load_img('/content/for_images/image00539.png',target_size =(64,64))\n",
        "test_image =image.img_to_array(test_image)\n",
        "#normalize test image\n",
        "test_image = test_image*(1/255)\n",
        "test_image =np.expand_dims(test_image, axis =0)\n",
        "result = classifier.predict(test_image)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zc_dpsABa93_",
        "outputId": "ede5fd6d-a94a-4b3b-ec30-ed1288efb417"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 206ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNBcMHQjFkV1",
        "outputId": "8cef8ecd-2a6f-4b26-bddc-c13af466ef02"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-47.037594 -56.56745   28.314947  15.006702  30.549433]]\n"
          ]
        }
      ]
    }
  ]
}